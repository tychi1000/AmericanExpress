{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import data science packages pandas, numpy, matplotlib, seaborn, and sklearn'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''import plotly'''\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "import warnings, gc\n",
    "import matplotlib.colors\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# init_notebook_mode(connected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import data from csv file'''\n",
    "train = pd.read_feather('C:/Users/tyler/Desktop/Kaggle/Amex Feather Data/train_data.ftr')\n",
    "#Subsample data\n",
    "#train = train.sample(frac=0.1, random_state=42)\n",
    "test = pd.read_feather('C:/Users/tyler/Desktop/Kaggle/Amex Feather Data/test_data.ftr')\n",
    "#Subsample data\n",
    "#test = test.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function that changes S_2 etc to Spend 2 etc'''\n",
    "def change_col_name(df):\n",
    "    df.columns = [x.replace('S_', 'Spend ') if x.startswith('S_') else x for x in df.columns]\n",
    "    df.columns = [x.replace('R_', 'Risk ') if x.startswith('R_') else x for x in df.columns]\n",
    "    df.columns = [x.replace('P_', 'Payment ') if x.startswith('P_') else x for x in df.columns]\n",
    "    df.columns = [x.replace('D_', 'Delinquency ') if x.startswith('D_') else x for x in df.columns]\n",
    "    df.columns = [x.replace('B_', 'Balance ') if x.startswith('B_') else x for x in df.columns]\n",
    "    df.columns = [x.replace('target', 'Target') if x.startswith('target') else x for x in df.columns]\n",
    "    return df\n",
    "\n",
    "change_col_name(train)\n",
    "change_col_name(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['Balance 30', 'Balance 38', 'Delinquency 63', 'Delinquency 64', 'Delinquency 66', 'Delinquency 68',\n",
    "          'Delinquency 114', 'Delinquency 116', 'Delinquency 117', 'Delinquency 120', 'Delinquency 126']\n",
    "          \n",
    "num_cols = [col for col in train.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "for col in cat_cols[:-1]:\n",
    "    train[col] = enc.fit_transform(train[col])\n",
    "    test[col] = enc.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of Column Types\n",
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col, train[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    print(col, train[col].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Spend 2']\n",
    "# del test['Spend 2']\n",
    "del train['customer_ID']\n",
    "del num_cols[-1:]\n",
    "del num_cols[:2]\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast all categorical columns to string\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].astype(str)\n",
    "\n",
    "#Cast all categorical columns to string\n",
    "# for col in cat_cols:\n",
    "#     test[col] = test[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing_value')),\n",
    "    ('one hot encode', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    (\"cat\", categorical_transformer, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run categorical transformer on data\n",
    "ohe_df = categorical_transformer.fit_transform(train[cat_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory size of one_df in MB\n",
    "ohe_df.data.nbytes / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory size of train in MB\n",
    "train.memory_usage().sum() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_num_cols = numeric_transformer.fit_transform(train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine transformed_num_cols and ohe_df\n",
    "train_transformed = np.concatenate([transformed_num_cols, ohe_df.toarray()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed = pd.DataFrame(train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#memory usage of train_transformed in MB\n",
    "train_transformed.memory_usage().sum() / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "X = train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver='sag', verbose=1, n_jobs=-1, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print('Accuracy of Random Forest Classifier on test set: {:.2f}'.format(rfc.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data and preprocess\n",
    "# test = pd.read_feather('C:/Users/tyler/Desktop/Kaggle/Amex Feather Data/test_data.ftr')\n",
    "# change_col_name(test)\n",
    "# del test['Spend 2']\n",
    "# del test['customer_ID']\n",
    "# test[cat_cols] = test[cat_cols].astype(str)\n",
    "# test_transformed = preprocessor.transform(test)\n",
    "# test_transformed = pd.DataFrame(test_transformed)\n",
    "# test_transformed\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BELOW IS MODELS WITH NO IMPUTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols=['Balance 30', 'Balance 38', 'Delinquency 63', 'Delinquency 64', 'Delinquency 66', 'Delinquency 68',\n",
    "          'Delinquency 114', 'Delinquency 116', 'Delinquency 117', 'Delinquency 120', 'Delinquency 126', 'Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Select numerical columns with no missing values and not in cat_cols'''\n",
    "num_cols = [col for col in train.columns if train[col].dtype != 'object' and train[col].isnull().sum() == 0 and col not in cat_cols]\n",
    "num_cols.remove('Spend 2')\n",
    "len(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''train test split sklearn'''\n",
    "X = train[num_cols]\n",
    "y = train['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression with validation set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "#Plot roc_curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix of logistic regression using plotly\n",
    "import plotly.figure_factory as ff\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm = np.around(cm, decimals=2)\n",
    "fig = ff.create_annotated_heatmap(cm, x=['Predicted 0', 'Predicted 1'], y=['Actual 0', 'Actual 1'], colorscale='Viridis')\n",
    "fig.update_layout(title_text='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run logisitc regression with normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "Scaled_X_train = scaler.transform(X_train)\n",
    "Scaled_X_test = scaler.transform(X_test)\n",
    "logreg.fit(Scaled_X_train, y_train)\n",
    "y_pred = logreg.predict(Scaled_X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(Scaled_X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(verbose=1, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "print('Accuracy of Random Forest Classifier on test set: {:.2f}'.format(rfc.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make ensemble of logistic regression and random forest classifier\n",
    "ensemble = (logreg.predict_proba(X_test) + rfc.predict_proba(X_test))/2\n",
    "ensemble_pred = np.argmax(ensemble, axis=1)\n",
    "#Find Accuracy of ensemble\n",
    "print('Accuracy of Ensemble on test set: {:.2f}'.format(accuracy_score(y_test, ensemble_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Graph of Spend 2'''\n",
    "fig = px.histogram(train, x=\"Spend 2\", color=\"Target\", marginal=\"box\", hover_data=train.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''check which cat_cols do not have any null values'''\n",
    "for col in cat_cols[:-1]:\n",
    "    print(col, train[col].isnull().sum())\n",
    "    print(col, test[col].isnull().sum())\n",
    "\n",
    "'''Run test between train and test set to see if they are from the same distribution'''\n",
    "for col in ['Delinquency 63', 'Delinquency 64']:\n",
    "    print(col, stats.ks_2samp(train[col], test[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['Delinquency 63'].value_counts())\n",
    "print(test['Delinquency 63'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Calculate observed frequency for each category in each dataframe\n",
    "train_observed_freq = train['Delinquency 63'].value_counts()\n",
    "test_observed_freq = test['Delinquency 63'].value_counts()\n",
    "\n",
    "# Calculate the expected frequency for each category in each dataframe\n",
    "train_expected_freq = train['Delinquency 63'].value_counts(normalize=True) * len(train)\n",
    "test_expected_freq = test['Delinquency 63'].value_counts(normalize=True) * len(test)\n",
    "\n",
    "# Compute Chi-Squared statistic and p-value for train data\n",
    "chi2, p, dof, ex = stats.chi2_contingency([train_observed_freq, train_expected_freq])\n",
    "print(f'Chi-Squared Statistic (Train): {chi2:.3f}')\n",
    "print(f'p-value (Train): {p:.3f}')\n",
    "\n",
    "# Compute Chi-Squared statistic and p-value for test data\n",
    "chi2, p, dof, ex = stats.chi2_contingency([test_observed_freq, test_expected_freq])\n",
    "print(f'Chi-Squared Statistic (Test): {chi2:.3f}')\n",
    "print(f'p-value (Test): {p:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_expected_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expected_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Run test between train and test set to see if they are from the same distribution'''\n",
    "for col in ['Delinquency 63', 'Delinquency 64']:\n",
    "    print(col, stats.ks_2samp(train[col], test[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train63 = le.fit_transform(train['Delinquency 63'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot delinquency 63 and 64'''\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Delinquency 63', 'Delinquency 64'))\n",
    "fig.add_trace(go.Histogram(x=train['Delinquency 63'], name='Train'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=test['Delinquency 63'], name='Test'), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=train['Delinquency 64'], name='Train'), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=test['Delinquency 64'], name='Test'), row=1, col=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train['Spend 2'].groupby(train.customer_ID).max().value_counts().reset_index()\n",
    "temp\n",
    "temp['index'] = pd.to_datetime(temp['Spend 2'])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot histogram of S_2'''\n",
    "fig = px.histogram(train, x=\"Spend 2\", nbins=700, title='Spend Histogram')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''select numerical columns in dataframe'''\n",
    "train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''returns t test result between two dataframes'''\n",
    "from scipy.stats import ttest_ind\n",
    "def t_test(df1, df2, col):\n",
    "    return ttest_ind(df1[col], df2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test(train, test, 'Balance 24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict(layout=go.Layout(font=dict(family=\"Franklin Gothic\", size=12), \n",
    "                           height=500, width=1000))\n",
    "                           \n",
    "target=train.Target.value_counts(normalize=True)\n",
    "target.rename(index={1:'Default',0:'Paid'},inplace=True)\n",
    "pal, color=['#016CC9','#DEB078'], ['#8DBAE2','#EDD3B3']\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Pie(labels=target.index, values=target*100, hole=.45, \n",
    "                     showlegend=True,sort=False, \n",
    "                     marker=dict(colors=color,line=dict(color=pal,width=2.5)),\n",
    "                     hovertemplate = \"%{label} Accounts: %{value:.2f}%<extra></extra>\"))\n",
    "fig.update_layout(template=temp, title='Target Distribution', \n",
    "                  legend=dict(traceorder='reversed',y=1.05,x=0),\n",
    "                  uniformtext_minsize=15, uniformtext_mode='hide',width=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''plotly express bar charts for Spend 1-30'''\n",
    "# fig = make_subplots(rows=10, cols=3, subplot_titles=['Spend 1', 'Spend 2', 'Spend 3', 'Spend 4', 'Spend 5', 'Spend 6', 'Spend 7', 'Spend 8', 'Spend 9', 'Spend 10', 'Spend 11', 'Spend 12', 'Spend 13', 'Spend 14', 'Spend 15', 'Spend 16', 'Spend 17', 'Spend 18', 'Spend 19', 'Spend 20', 'Spend 21', 'Spend 22', 'Spend 23', 'Spend 24', 'Spend 25', 'Spend 26', 'Spend 27', 'Spend 28', 'Spend 29', 'Spend 30'])\n",
    "# for i, col in enumerate(['Spend 1', 'Spend 2', 'Spend 3', 'Spend 4', 'Spend 5', 'Spend 6', 'Spend 7', 'Spend 8', 'Spend 9', 'Spend 10', 'Spend 11', 'Spend 12', 'Spend 13', 'Spend 14', 'Spend 15', 'Spend 16', 'Spend 17', 'Spend 18', 'Spend 19', 'Spend 20', 'Spend 21', 'Spend 22', 'Spend 23', 'Spend 24', 'Spend 25', 'Spend 26', 'Spend 27', 'Spend 28', 'Spend 29', 'Spend 30']):\n",
    "#     row = i//3 + 1\n",
    "#     col = i%3 + 1\n",
    "#     fig.add_trace(go.Bar(x=train[col].value_counts().index, y=train[col].value_counts().values), row=row, col=col)\n",
    "# fig.update_layout(height=1000, width=1000, title_text=\"Distribution of Spend Variables\")\n",
    "# fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Investigation Ideas from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload\n",
    "train = pd.read_feather('C:/Users/tyler/Desktop/Kaggle/Amex Feather Data/train_data.ftr')\n",
    "test = pd.read_feather('C:/Users/tyler/Desktop/Kaggle/Amex Feather Data/test_data.ftr')\n",
    "\n",
    "change_col_name(train)\n",
    "change_col_name(test)\n",
    "\n",
    "train = train.groupby('customer_ID').tail(1).set_index('customer_ID')\n",
    "test = test.groupby('customer_ID').tail(1).set_index('customer_ID')\n",
    "del test['Spend 2']\n",
    "del train['Spend 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provided by Amex in a Kaggle notebook\n",
    "\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea for lgbm model from this kaggle notebook by Kelli Belcher https://www.kaggle.com/code/kellibelcher/amex-default-prediction-eda-lgbm-baseline#4-%7C-Default-Prediction\n",
    "\n",
    "enc = LabelEncoder()\n",
    "for col in cat_cols[:-1]:\n",
    "    train[col] = enc.fit_transform(train[col])\n",
    "    test[col] = enc.transform(test[col])\n",
    "\n",
    "X=train.drop(['Target'],axis=1)\n",
    "y=train['Target']\n",
    "y_valid, gbm_val_probs, gbm_test_preds, gini=[],[],[],[]\n",
    "ft_importance=pd.DataFrame(index=X.columns)\n",
    "sk_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(sk_fold.split(X, y)):\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx,:], y[val_idx]\n",
    "    \n",
    "    print(f'Train shape {X_train.shape}, {y_train.shape}. Valid shape: {X_val.shape}, {y_val.shape}')\n",
    "\n",
    "    \n",
    "    gbm = LGBMClassifier().fit(X_train, y_train, \n",
    "                                eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "                                callbacks=[early_stopping(200), log_evaluation(200)],\n",
    "                                eval_metric=['auc'])\n",
    "    \n",
    "    gbm_prob = gbm.predict_proba(X_val)[:,1]\n",
    "    gbm_val_probs.append(gbm_prob)\n",
    "    y_valid.append(y_val)\n",
    "    \n",
    "    y_pred=pd.DataFrame(data={'prediction':gbm_prob})\n",
    "    y_true=pd.DataFrame(data={'target':y_val.reset_index(drop=True)})\n",
    "    gini_score=amex_metric(y_true = y_true, y_pred = y_pred)\n",
    "    gini.append(gini_score)\n",
    "    \n",
    "    auc_score=roc_auc_score(y_val, gbm_prob)\n",
    "    gbm_test_preds.append(gbm.predict_proba(test)[:,1])\n",
    "\n",
    "    print(f'Fold {fold} Gini score: {gini_score}, AUC score: {auc_score}')\n",
    "\n",
    "del X_train, y_train, X_val, y_val\n",
    "\n",
    "change_col_name(train)\n",
    "change_col_name(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[col for col in train.columns if (col.startswith(('S','T'))) & (col not in cat_cols[:-1])]\n",
    "plot_df=train[cols]\n",
    "\n",
    "for col in plot_df:\n",
    "    plot_df[col]=plot_df[col].astype(float)\n",
    "\n",
    "#Plot the distributions of the spend and target variables with loop\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for i, col in enumerate(plot_df.columns):\n",
    "    sns.distplot(plot_df[col], ax=ax[i//2, i%2])\n",
    "    ax[i//2, i%2].set_title(col)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e1f844d1d60092c6e4cefec21308482af90357ffc7fd44ea5e48912c1a7104"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
